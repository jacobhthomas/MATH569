{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e34553e6",
   "metadata": {},
   "source": [
    "# Subset Selection Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44b02a2",
   "metadata": {},
   "source": [
    "## Code from Starter Code for Merging the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01da0e9c",
   "metadata": {},
   "source": [
    "#### Making a singular data table of all our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "315e129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "514098a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic = pd.read_csv('reduced-Chicago_Traffic_Tracker_-_Historical_Congestion_Estimates_by_Segment_-_2011-2018_20240329.csv')\n",
    "weather = pd.read_csv('weather-chicago, il 2018-04-01 to 2018-05-01.csv')\n",
    "crashes = pd.read_csv(\"Traffic_Crashes_-_Crashes_20240329.csv\")\n",
    "segments = pd.read_csv(\"segments_dict.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1a32e439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traffic_time_to_weather_time(instr):\n",
    "    date = instr.split()[0]\n",
    "    #print(date)\n",
    "    time = instr.split()[1]\n",
    "    ampm = instr.split()[2]\n",
    "    \n",
    "    year = date.split(\"/\")[2]\n",
    "    month = date.split(\"/\")[0]\n",
    "    day = date.split(\"/\")[1]\n",
    "    \n",
    "    hour = time.split(\":\")[0] if ampm == \"AM\" else str(int(time.split(\":\")[0])+12)\n",
    "    \n",
    "    return (year+\"-\"+month+\"-\"+day+\"T\"+hour+\":00:00\")\n",
    "def make_new_time(row):\n",
    "    return traffic_time_to_weather_time(row[\"TIME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "83ccd659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME</th>\n",
       "      <th>SEGMENTID</th>\n",
       "      <th>BUS COUNT</th>\n",
       "      <th>MESSAGE COUNT</th>\n",
       "      <th>SPEED</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04/30/2018 11:50:28 PM</td>\n",
       "      <td>1133</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>2018-04-30T23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04/30/2018 11:50:28 PM</td>\n",
       "      <td>1133</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>2018-04-30T23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04/30/2018 11:50:28 PM</td>\n",
       "      <td>1153</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>2018-04-30T23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04/30/2018 11:50:28 PM</td>\n",
       "      <td>1153</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>2018-04-30T23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04/30/2018 11:50:28 PM</td>\n",
       "      <td>1178</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>2018-04-30T23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577596</th>\n",
       "      <td>04/01/2018 12:01:06 AM</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>2018-04-01T12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577597</th>\n",
       "      <td>04/01/2018 12:01:06 AM</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2018-04-01T12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577598</th>\n",
       "      <td>04/01/2018 12:01:06 AM</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>2018-04-01T12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577599</th>\n",
       "      <td>04/01/2018 12:01:06 AM</td>\n",
       "      <td>206</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>2018-04-01T12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577600</th>\n",
       "      <td>04/01/2018 12:01:06 AM</td>\n",
       "      <td>210</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>2018-04-01T12:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2577601 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           TIME  SEGMENTID  BUS COUNT                  \\\n",
       "0        04/30/2018 11:50:28 PM       1133                          1   \n",
       "1        04/30/2018 11:50:28 PM       1133                          1   \n",
       "2        04/30/2018 11:50:28 PM       1153                          1   \n",
       "3        04/30/2018 11:50:28 PM       1153                          1   \n",
       "4        04/30/2018 11:50:28 PM       1178                          1   \n",
       "...                         ...        ...                        ...   \n",
       "2577596  04/01/2018 12:01:06 AM        203                          1   \n",
       "2577597  04/01/2018 12:01:06 AM        204                          1   \n",
       "2577598  04/01/2018 12:01:06 AM        205                          1   \n",
       "2577599  04/01/2018 12:01:06 AM        206                          1   \n",
       "2577600  04/01/2018 12:01:06 AM        210                          1   \n",
       "\n",
       "         MESSAGE COUNT  SPEED             datetime  \n",
       "0                    5     27  2018-04-30T23:00:00  \n",
       "1                    5     27  2018-04-30T23:00:00  \n",
       "2                    4     23  2018-04-30T23:00:00  \n",
       "3                    4     23  2018-04-30T23:00:00  \n",
       "4                    5     16  2018-04-30T23:00:00  \n",
       "...                ...    ...                  ...  \n",
       "2577596             12     18  2018-04-01T12:00:00  \n",
       "2577597              1     24  2018-04-01T12:00:00  \n",
       "2577598              7     24  2018-04-01T12:00:00  \n",
       "2577599              6     24  2018-04-01T12:00:00  \n",
       "2577600              6     20  2018-04-01T12:00:00  \n",
       "\n",
       "[2577601 rows x 6 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic[\"datetime\"] = traffic.apply(make_new_time, axis=1)\n",
    "traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bada31a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TIME', 'SEGMENTID', 'BUS COUNT                ', 'MESSAGE COUNT',\n",
       "       'SPEED', 'datetime', 'name', 'temp', 'feelslike', 'dew', 'humidity',\n",
       "       'precip', 'precipprob', 'preciptype', 'snow', 'snowdepth', 'windgust',\n",
       "       'windspeed', 'winddir', 'sealevelpressure', 'cloudcover', 'visibility',\n",
       "       'solarradiation', 'solarenergy', 'uvindex', 'severerisk', 'conditions',\n",
       "       'icon', 'stations'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_merged = traffic.merge(weather, how='left')\n",
    "traffic_merged.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fb053c",
   "metadata": {},
   "source": [
    "## Data Exploration and Removing Useless Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007d2b2e",
   "metadata": {},
   "source": [
    "In the below histogram, note that most values for preciptype were nan so there's not a lot of information in this column \n",
    "\n",
    "For that reason, it's best to remove this feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9b4c4874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2306808.,       0.,       0.,  169268.,       0.,       0.,\n",
       "          95781.,       0.,       0.,    5744.]),\n",
       " array([0. , 0.3, 0.6, 0.9, 1.2, 1.5, 1.8, 2.1, 2.4, 2.7, 3. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(traffic_merged['preciptype'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2586a49",
   "metadata": {},
   "source": [
    "The below histogram shows the extremely skewed right and asymmetric distribution of precipitation amounts. Consider removing this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2b3aba49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.389118e+06, 3.261900e+04, 1.354800e+04, 9.838000e+03,\n",
       "        5.079000e+03, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 8.420000e+02]),\n",
       " array([0.    , 0.0117, 0.0234, 0.0351, 0.0468, 0.0585, 0.0702, 0.0819,\n",
       "        0.0936, 0.1053, 0.117 ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(traffic_merged['precip'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a26f4d8",
   "metadata": {},
   "source": [
    "We drop the following features for the following reasons: \n",
    " - Bus count: not related to traffic (assuming busses aren't a significant factor to flow of traffic in a segment, might be wrong, so possibly keep this) \n",
    " - Message count: not related to traffic or weather \n",
    " - Datetime: we already have a time column (TIME)\n",
    " - name: This is just the name of the city, which is Chicago for all columns anyway, and a proxy for location, which we already have in the segment \n",
    " - Precipprob: Is just a prediction for precipitation, not an actual indicator of current weather\n",
    " - snow: see previous bullet \n",
    " - winddir: angle is numeric but cyclical, so it'll take some further analysis to get useful info from this \n",
    " - windspeed: windgust is a more accurate measure of windspeed anyway, and if it's nan, then we can coerce it to the windspeed value (I believe this does not happen for this dataset) \n",
    " - severerisk: a generalization of weather not related to physical data \n",
    " - icon: similar to severerisk\n",
    " - stations: not a physical observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "45fdfabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_merged = traffic_merged.drop(['BUS COUNT                ', 'MESSAGE COUNT', 'datetime', 'name', 'precipprob', \n",
    "               'snow', 'windspeed', 'winddir', 'severerisk', 'icon', 'stations'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300e8ac5",
   "metadata": {},
   "source": [
    "### Removing nan values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9b0f78",
   "metadata": {},
   "source": [
    "What we wanna do here is sort the entries by time. We do this because if the entries are sorted by time, then we can fill nan values with the nearest availible time \n",
    "\n",
    "If we make a column which contains datetime objects, we can compare 2 time values and thus sort all the rows that way "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d002d850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME</th>\n",
       "      <th>SEGMENTID</th>\n",
       "      <th>SPEED</th>\n",
       "      <th>temp</th>\n",
       "      <th>feelslike</th>\n",
       "      <th>dew</th>\n",
       "      <th>humidity</th>\n",
       "      <th>precip</th>\n",
       "      <th>preciptype</th>\n",
       "      <th>snowdepth</th>\n",
       "      <th>windgust</th>\n",
       "      <th>sealevelpressure</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>visibility</th>\n",
       "      <th>solarradiation</th>\n",
       "      <th>solarenergy</th>\n",
       "      <th>uvindex</th>\n",
       "      <th>conditions</th>\n",
       "      <th>std_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04/30/2018 11:50:28 PM</td>\n",
       "      <td>1133</td>\n",
       "      <td>27</td>\n",
       "      <td>67.2</td>\n",
       "      <td>67.2</td>\n",
       "      <td>29.4</td>\n",
       "      <td>24.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.7</td>\n",
       "      <td>1014.9</td>\n",
       "      <td>24.2</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>2018-04-30 23:50:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04/30/2018 11:50:28 PM</td>\n",
       "      <td>1133</td>\n",
       "      <td>27</td>\n",
       "      <td>67.2</td>\n",
       "      <td>67.2</td>\n",
       "      <td>29.4</td>\n",
       "      <td>24.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.7</td>\n",
       "      <td>1014.9</td>\n",
       "      <td>24.2</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>2018-04-30 23:50:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04/30/2018 11:50:28 PM</td>\n",
       "      <td>1153</td>\n",
       "      <td>23</td>\n",
       "      <td>67.2</td>\n",
       "      <td>67.2</td>\n",
       "      <td>29.4</td>\n",
       "      <td>24.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.7</td>\n",
       "      <td>1014.9</td>\n",
       "      <td>24.2</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>2018-04-30 23:50:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04/30/2018 11:50:28 PM</td>\n",
       "      <td>1153</td>\n",
       "      <td>23</td>\n",
       "      <td>67.2</td>\n",
       "      <td>67.2</td>\n",
       "      <td>29.4</td>\n",
       "      <td>24.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.7</td>\n",
       "      <td>1014.9</td>\n",
       "      <td>24.2</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>2018-04-30 23:50:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04/30/2018 11:50:28 PM</td>\n",
       "      <td>1178</td>\n",
       "      <td>16</td>\n",
       "      <td>67.2</td>\n",
       "      <td>67.2</td>\n",
       "      <td>29.4</td>\n",
       "      <td>24.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.7</td>\n",
       "      <td>1014.9</td>\n",
       "      <td>24.2</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>2018-04-30 23:50:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577596</th>\n",
       "      <td>04/01/2018 12:01:06 AM</td>\n",
       "      <td>203</td>\n",
       "      <td>18</td>\n",
       "      <td>32.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>14.3</td>\n",
       "      <td>45.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>78.4</td>\n",
       "      <td>9.9</td>\n",
       "      <td>496.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>2018-04-01 00:01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577597</th>\n",
       "      <td>04/01/2018 12:01:06 AM</td>\n",
       "      <td>204</td>\n",
       "      <td>24</td>\n",
       "      <td>32.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>14.3</td>\n",
       "      <td>45.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>78.4</td>\n",
       "      <td>9.9</td>\n",
       "      <td>496.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>2018-04-01 00:01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577598</th>\n",
       "      <td>04/01/2018 12:01:06 AM</td>\n",
       "      <td>205</td>\n",
       "      <td>24</td>\n",
       "      <td>32.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>14.3</td>\n",
       "      <td>45.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>78.4</td>\n",
       "      <td>9.9</td>\n",
       "      <td>496.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>2018-04-01 00:01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577599</th>\n",
       "      <td>04/01/2018 12:01:06 AM</td>\n",
       "      <td>206</td>\n",
       "      <td>24</td>\n",
       "      <td>32.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>14.3</td>\n",
       "      <td>45.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>78.4</td>\n",
       "      <td>9.9</td>\n",
       "      <td>496.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>2018-04-01 00:01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577600</th>\n",
       "      <td>04/01/2018 12:01:06 AM</td>\n",
       "      <td>210</td>\n",
       "      <td>20</td>\n",
       "      <td>32.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>14.3</td>\n",
       "      <td>45.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>78.4</td>\n",
       "      <td>9.9</td>\n",
       "      <td>496.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>2018-04-01 00:01:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2577601 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           TIME  SEGMENTID  SPEED  temp  feelslike   dew  \\\n",
       "0        04/30/2018 11:50:28 PM       1133     27  67.2       67.2  29.4   \n",
       "1        04/30/2018 11:50:28 PM       1133     27  67.2       67.2  29.4   \n",
       "2        04/30/2018 11:50:28 PM       1153     23  67.2       67.2  29.4   \n",
       "3        04/30/2018 11:50:28 PM       1153     23  67.2       67.2  29.4   \n",
       "4        04/30/2018 11:50:28 PM       1178     16  67.2       67.2  29.4   \n",
       "...                         ...        ...    ...   ...        ...   ...   \n",
       "2577596  04/01/2018 12:01:06 AM        203     18  32.9       27.8  14.3   \n",
       "2577597  04/01/2018 12:01:06 AM        204     24  32.9       27.8  14.3   \n",
       "2577598  04/01/2018 12:01:06 AM        205     24  32.9       27.8  14.3   \n",
       "2577599  04/01/2018 12:01:06 AM        206     24  32.9       27.8  14.3   \n",
       "2577600  04/01/2018 12:01:06 AM        210     20  32.9       27.8  14.3   \n",
       "\n",
       "         humidity  precip preciptype  snowdepth  windgust  sealevelpressure  \\\n",
       "0           24.24     0.0        NaN        0.0      27.7            1014.9   \n",
       "1           24.24     0.0        NaN        0.0      27.7            1014.9   \n",
       "2           24.24     0.0        NaN        0.0      27.7            1014.9   \n",
       "3           24.24     0.0        NaN        0.0      27.7            1014.9   \n",
       "4           24.24     0.0        NaN        0.0      27.7            1014.9   \n",
       "...           ...     ...        ...        ...       ...               ...   \n",
       "2577596     45.72     0.0        NaN        0.0      13.2            1026.0   \n",
       "2577597     45.72     0.0        NaN        0.0      13.2            1026.0   \n",
       "2577598     45.72     0.0        NaN        0.0      13.2            1026.0   \n",
       "2577599     45.72     0.0        NaN        0.0      13.2            1026.0   \n",
       "2577600     45.72     0.0        NaN        0.0      13.2            1026.0   \n",
       "\n",
       "         cloudcover  visibility  solarradiation  solarenergy  uvindex  \\\n",
       "0              24.2         9.9             0.0          0.0      0.0   \n",
       "1              24.2         9.9             0.0          0.0      0.0   \n",
       "2              24.2         9.9             0.0          0.0      0.0   \n",
       "3              24.2         9.9             0.0          0.0      0.0   \n",
       "4              24.2         9.9             0.0          0.0      0.0   \n",
       "...             ...         ...             ...          ...      ...   \n",
       "2577596        78.4         9.9           496.0          1.8      5.0   \n",
       "2577597        78.4         9.9           496.0          1.8      5.0   \n",
       "2577598        78.4         9.9           496.0          1.8      5.0   \n",
       "2577599        78.4         9.9           496.0          1.8      5.0   \n",
       "2577600        78.4         9.9           496.0          1.8      5.0   \n",
       "\n",
       "               conditions        std_datetime  \n",
       "0        Partially cloudy 2018-04-30 23:50:28  \n",
       "1        Partially cloudy 2018-04-30 23:50:28  \n",
       "2        Partially cloudy 2018-04-30 23:50:28  \n",
       "3        Partially cloudy 2018-04-30 23:50:28  \n",
       "4        Partially cloudy 2018-04-30 23:50:28  \n",
       "...                   ...                 ...  \n",
       "2577596  Partially cloudy 2018-04-01 00:01:06  \n",
       "2577597  Partially cloudy 2018-04-01 00:01:06  \n",
       "2577598  Partially cloudy 2018-04-01 00:01:06  \n",
       "2577599  Partially cloudy 2018-04-01 00:01:06  \n",
       "2577600  Partially cloudy 2018-04-01 00:01:06  \n",
       "\n",
       "[2577601 rows x 19 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_std_time(row):\n",
    "    return datetime.strptime(row[\"TIME\"], '%m/%d/%Y %I:%M:%S %p')\n",
    "traffic_merged[\"std_datetime\"] = traffic.apply(make_std_time, axis=1)\n",
    "traffic_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1419f553",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_merged = traffic_merged.sort_values(by=['std_datetime','SEGMENTID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4e5a38eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME</th>\n",
       "      <th>SEGMENTID</th>\n",
       "      <th>SPEED</th>\n",
       "      <th>temp</th>\n",
       "      <th>feelslike</th>\n",
       "      <th>dew</th>\n",
       "      <th>humidity</th>\n",
       "      <th>precip</th>\n",
       "      <th>preciptype</th>\n",
       "      <th>snowdepth</th>\n",
       "      <th>windgust</th>\n",
       "      <th>sealevelpressure</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>visibility</th>\n",
       "      <th>solarradiation</th>\n",
       "      <th>solarenergy</th>\n",
       "      <th>uvindex</th>\n",
       "      <th>conditions</th>\n",
       "      <th>std_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2577550</th>\n",
       "      <td>04/01/2018 12:01:06 AM</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>32.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>14.3</td>\n",
       "      <td>45.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rain</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>78.4</td>\n",
       "      <td>9.9</td>\n",
       "      <td>496.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>2018-04-01 00:01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577551</th>\n",
       "      <td>04/01/2018 12:01:06 AM</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>32.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>14.3</td>\n",
       "      <td>45.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rain</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>78.4</td>\n",
       "      <td>9.9</td>\n",
       "      <td>496.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>2018-04-01 00:01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577552</th>\n",
       "      <td>04/01/2018 12:01:06 AM</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>32.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>14.3</td>\n",
       "      <td>45.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rain</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>78.4</td>\n",
       "      <td>9.9</td>\n",
       "      <td>496.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>2018-04-01 00:01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577553</th>\n",
       "      <td>04/01/2018 12:01:06 AM</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>32.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>14.3</td>\n",
       "      <td>45.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rain</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>78.4</td>\n",
       "      <td>9.9</td>\n",
       "      <td>496.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>2018-04-01 00:01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577554</th>\n",
       "      <td>04/01/2018 12:01:06 AM</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>32.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>14.3</td>\n",
       "      <td>45.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rain</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>78.4</td>\n",
       "      <td>9.9</td>\n",
       "      <td>496.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>2018-04-01 00:01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>04/30/2018 11:50:28 PM</td>\n",
       "      <td>1305</td>\n",
       "      <td>20</td>\n",
       "      <td>67.2</td>\n",
       "      <td>67.2</td>\n",
       "      <td>29.4</td>\n",
       "      <td>24.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rain</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.7</td>\n",
       "      <td>1014.9</td>\n",
       "      <td>24.2</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>2018-04-30 23:50:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>04/30/2018 11:50:28 PM</td>\n",
       "      <td>1307</td>\n",
       "      <td>25</td>\n",
       "      <td>67.2</td>\n",
       "      <td>67.2</td>\n",
       "      <td>29.4</td>\n",
       "      <td>24.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rain</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.7</td>\n",
       "      <td>1014.9</td>\n",
       "      <td>24.2</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>2018-04-30 23:50:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>04/30/2018 11:50:28 PM</td>\n",
       "      <td>1307</td>\n",
       "      <td>25</td>\n",
       "      <td>67.2</td>\n",
       "      <td>67.2</td>\n",
       "      <td>29.4</td>\n",
       "      <td>24.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rain</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.7</td>\n",
       "      <td>1014.9</td>\n",
       "      <td>24.2</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>2018-04-30 23:50:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>04/30/2018 11:50:28 PM</td>\n",
       "      <td>1309</td>\n",
       "      <td>29</td>\n",
       "      <td>67.2</td>\n",
       "      <td>67.2</td>\n",
       "      <td>29.4</td>\n",
       "      <td>24.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rain</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.7</td>\n",
       "      <td>1014.9</td>\n",
       "      <td>24.2</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>2018-04-30 23:50:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>04/30/2018 11:50:28 PM</td>\n",
       "      <td>1309</td>\n",
       "      <td>29</td>\n",
       "      <td>67.2</td>\n",
       "      <td>67.2</td>\n",
       "      <td>29.4</td>\n",
       "      <td>24.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rain</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.7</td>\n",
       "      <td>1014.9</td>\n",
       "      <td>24.2</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>2018-04-30 23:50:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2577601 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           TIME  SEGMENTID  SPEED  temp  feelslike   dew  \\\n",
       "2577550  04/01/2018 12:01:06 AM          1     25  32.9       27.8  14.3   \n",
       "2577551  04/01/2018 12:01:06 AM          2     20  32.9       27.8  14.3   \n",
       "2577552  04/01/2018 12:01:06 AM          7     32  32.9       27.8  14.3   \n",
       "2577553  04/01/2018 12:01:06 AM          8     27  32.9       27.8  14.3   \n",
       "2577554  04/01/2018 12:01:06 AM          9     28  32.9       27.8  14.3   \n",
       "...                         ...        ...    ...   ...        ...   ...   \n",
       "79       04/30/2018 11:50:28 PM       1305     20  67.2       67.2  29.4   \n",
       "80       04/30/2018 11:50:28 PM       1307     25  67.2       67.2  29.4   \n",
       "81       04/30/2018 11:50:28 PM       1307     25  67.2       67.2  29.4   \n",
       "82       04/30/2018 11:50:28 PM       1309     29  67.2       67.2  29.4   \n",
       "83       04/30/2018 11:50:28 PM       1309     29  67.2       67.2  29.4   \n",
       "\n",
       "         humidity  precip preciptype  snowdepth  windgust  sealevelpressure  \\\n",
       "2577550     45.72     0.0       rain        0.0      13.2            1026.0   \n",
       "2577551     45.72     0.0       rain        0.0      13.2            1026.0   \n",
       "2577552     45.72     0.0       rain        0.0      13.2            1026.0   \n",
       "2577553     45.72     0.0       rain        0.0      13.2            1026.0   \n",
       "2577554     45.72     0.0       rain        0.0      13.2            1026.0   \n",
       "...           ...     ...        ...        ...       ...               ...   \n",
       "79          24.24     0.0       rain        0.0      27.7            1014.9   \n",
       "80          24.24     0.0       rain        0.0      27.7            1014.9   \n",
       "81          24.24     0.0       rain        0.0      27.7            1014.9   \n",
       "82          24.24     0.0       rain        0.0      27.7            1014.9   \n",
       "83          24.24     0.0       rain        0.0      27.7            1014.9   \n",
       "\n",
       "         cloudcover  visibility  solarradiation  solarenergy  uvindex  \\\n",
       "2577550        78.4         9.9           496.0          1.8      5.0   \n",
       "2577551        78.4         9.9           496.0          1.8      5.0   \n",
       "2577552        78.4         9.9           496.0          1.8      5.0   \n",
       "2577553        78.4         9.9           496.0          1.8      5.0   \n",
       "2577554        78.4         9.9           496.0          1.8      5.0   \n",
       "...             ...         ...             ...          ...      ...   \n",
       "79             24.2         9.9             0.0          0.0      0.0   \n",
       "80             24.2         9.9             0.0          0.0      0.0   \n",
       "81             24.2         9.9             0.0          0.0      0.0   \n",
       "82             24.2         9.9             0.0          0.0      0.0   \n",
       "83             24.2         9.9             0.0          0.0      0.0   \n",
       "\n",
       "               conditions        std_datetime  \n",
       "2577550  Partially cloudy 2018-04-01 00:01:06  \n",
       "2577551  Partially cloudy 2018-04-01 00:01:06  \n",
       "2577552  Partially cloudy 2018-04-01 00:01:06  \n",
       "2577553  Partially cloudy 2018-04-01 00:01:06  \n",
       "2577554  Partially cloudy 2018-04-01 00:01:06  \n",
       "...                   ...                 ...  \n",
       "79       Partially cloudy 2018-04-30 23:50:28  \n",
       "80       Partially cloudy 2018-04-30 23:50:28  \n",
       "81       Partially cloudy 2018-04-30 23:50:28  \n",
       "82       Partially cloudy 2018-04-30 23:50:28  \n",
       "83       Partially cloudy 2018-04-30 23:50:28  \n",
       "\n",
       "[2577601 rows x 19 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_merged.ffill().bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2a702f31",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "NaN values found in column temp",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [85]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m traffic_merged\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m traffic_merged[column]\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;66;03m# If NaN values are found, raise an exception\u001b[39;00m\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;66;03m#print(column)\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN values found in column \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: NaN values found in column temp"
     ]
    }
   ],
   "source": [
    "for column in traffic_merged.columns:\n",
    "    if traffic_merged[column].isnull().any():\n",
    "        # If NaN values are found, raise an exception\n",
    "        #print(column)\n",
    "        raise Exception(f\"NaN values found in column {column}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0f05236f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing column: temp\n",
      "Used '34.7' to fill 126557 NaNs in temp\n",
      "First 10 unique values in temp after filling NaNs: [32.9 33.6 32.4 31.3 30.1 28.2 27.3 26.2 27.6 29.3]\n",
      "\n",
      "Processing column: feelslike\n",
      "Used '31.5' to fill 126557 NaNs in feelslike\n",
      "First 10 unique values in feelslike after filling NaNs: [27.8 24.8 23.2 22.8 22.  18.5 18.6 16.7 17.6 21.5]\n",
      "\n",
      "Processing column: dew\n",
      "Used '38.0' to fill 126557 NaNs in dew\n",
      "First 10 unique values in dew after filling NaNs: [14.3 19.9 18.7 17.3 15.6 12.9 11.5 10.7 10.  10.4]\n",
      "\n",
      "Processing column: humidity\n",
      "Used '94.79' to fill 126557 NaNs in humidity\n",
      "First 10 unique values in humidity after filling NaNs: [45.72 56.84 56.78 55.73 54.34 52.1  50.89 51.46 46.95 44.74]\n",
      "\n",
      "Processing column: precip\n",
      "Used '0.0' to fill 126557 NaNs in precip\n",
      "First 10 unique values in precip after filling NaNs: [0.    0.017 0.001 0.034 0.004 0.011 0.037 0.014 0.003 0.023]\n",
      "\n",
      "Processing column: preciptype\n",
      "Used 'rain,snow' to fill 2306808 NaNs in preciptype\n",
      "First 10 unique values in preciptype after filling NaNs: ['rain' 'rain,snow' 'snow']\n",
      "\n",
      "Processing column: snowdepth\n",
      "Used '0.0' to fill 126557 NaNs in snowdepth\n",
      "First 10 unique values in snowdepth after filling NaNs: [0.   0.08 0.12 0.2  0.16 0.43 0.39 0.35 0.31 0.24]\n",
      "\n",
      "Processing column: windgust\n",
      "Used '23.0' to fill 126557 NaNs in windgust\n",
      "First 10 unique values in windgust after filling NaNs: [13.2 20.1 20.4 19.7 19.2 19.  17.2 14.8 15.4 15. ]\n",
      "\n",
      "Processing column: sealevelpressure\n",
      "Used '1013.3' to fill 126557 NaNs in sealevelpressure\n",
      "First 10 unique values in sealevelpressure after filling NaNs: [1026.  1022.3 1022.5 1023.  1023.3 1024.  1024.5 1025.  1025.7 1025.6]\n",
      "\n",
      "Processing column: cloudcover\n",
      "Used '100.0' to fill 126557 NaNs in cloudcover\n",
      "First 10 unique values in cloudcover after filling NaNs: [78.4 44.  24.2 52.9 85.6 88.1 18.  80.9  0.  29.4]\n",
      "\n",
      "Processing column: visibility\n",
      "Used '9.9' to fill 126557 NaNs in visibility\n",
      "First 10 unique values in visibility after filling NaNs: [9.9 1.2 7.9 5.5 2.7 2.3 2.6 2.5 1.9 1.7]\n",
      "\n",
      "Processing column: solarradiation\n",
      "Used '0.0' to fill 126557 NaNs in solarradiation\n",
      "First 10 unique values in solarradiation after filling NaNs: [496.   0.  21. 138. 322. 331. 429. 524. 490. 253.]\n",
      "\n",
      "Processing column: solarenergy\n",
      "Used '0.0' to fill 126557 NaNs in solarenergy\n",
      "First 10 unique values in solarenergy after filling NaNs: [1.8 0.  0.1 0.5 1.2 1.5 1.9 0.9 0.3 1.3]\n",
      "\n",
      "Processing column: uvindex\n",
      "Used '0.0' to fill 126557 NaNs in uvindex\n",
      "First 10 unique values in uvindex after filling NaNs: [5. 0. 1. 3. 4. 2. 6. 8. 7. 9.]\n",
      "\n",
      "Processing column: conditions\n",
      "Used 'Partially cloudy' to fill 126557 NaNs in conditions\n",
      "First 10 unique values in conditions after filling NaNs: ['Partially cloudy' 'Clear' 'Overcast' 'Rain, Overcast' 'Snow, Overcast'\n",
      " 'Snow, Rain, Overcast']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for column in traffic_merged.columns:\n",
    "    nan_count_before = traffic_merged[column].isnull().sum()\n",
    "    if nan_count_before > 0:\n",
    "        print(f\"Processing column: {column}\")\n",
    "\n",
    "        traffic_merged[column] = traffic_merged[column].ffill().bfill()\n",
    "\n",
    "        most_common_value = traffic_merged[column].mode()[0]\n",
    "\n",
    "        nan_count_after = traffic_merged[column].isnull().sum()\n",
    "        if nan_count_after > 0:\n",
    "            traffic_merged[column].fillna(most_common_value, inplace=True)\n",
    "\n",
    "        if traffic_merged[column].isnull().any():\n",
    "            raise Exception(f\"NaN values still present in {column} after filling!\")\n",
    "\n",
    "        unique_values = traffic_merged[column].unique()[:10]\n",
    "        nan_filled = nan_count_before - nan_count_after\n",
    "\n",
    "        print(f\"Used '{most_common_value}' to fill {nan_filled} NaNs in {column}\")\n",
    "        print(f\"First 10 unique values in {column} after filling NaNs: {unique_values}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a7fe6e",
   "metadata": {},
   "source": [
    "### Adding extra columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8121ac2e",
   "metadata": {},
   "source": [
    "#### Turning time into numerical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d95e228",
   "metadata": {},
   "source": [
    "We make the day of week and time seperate numeric variables, and we hypothesize that the combo of those 2 will have good predictive power\n",
    "\n",
    "Note that this might backfire a lot, as traffic speeds over the day can be (and I'm guessing probably is) multimodal, and high values of either day or time closely line up with low values of the next day/week (respectively), so this might be a bad way to do it. Despite that, without knowledge of time series data processing techniques, I have no idea what else to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f121a1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_weekday(row):\n",
    "    cur_time = row[\"std_datetime\"]\n",
    "    return cur_time.weekday()\n",
    "def add_time(row):\n",
    "    cur_time = row[\"std_datetime\"]\n",
    "    return (cur_time.hour*3600)+(cur_time.minute*60)+(cur_time.second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "62b532a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_merged[\"weekday\"]=traffic_merged.apply(add_weekday, axis=1)\n",
    "traffic_merged[\"time_of_day\"]=traffic_merged.apply(add_time, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20765c2d",
   "metadata": {},
   "source": [
    "#### Replacing segment with lat/long"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6575879e",
   "metadata": {},
   "source": [
    "We replace segmens with a column for latitiude and longitude, that way we have a numeric value for which position is a meaningful metric\n",
    "\n",
    "Like with the time data, this is likely mutlimodal and doing simple regression on it will likely yield poor results\n",
    "\n",
    "We really should have done a different data set. But we're in too deep now and I'm really just hoping that us just using the techniques will give us a passing grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6a3ed497",
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_dict = {}\n",
    "for i in segments.iterrows():\n",
    "    #print(i[1][\"SEGMENTID\"])\n",
    "    long = (i[1][\"START_LONGITUDE\"] + i[1][\"END_LONGITUDE\"])/2\n",
    "    lat = (i[1][\" START_LATITUDE\"] + i[1][\" END_LATITUDE\"])/2\n",
    "    segments_dict[i[1][\"SEGMENTID\"]] = (lat, long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "71066c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lat(row):\n",
    "    return segments_dict[row[\"SEGMENTID\"]][0]\n",
    "def add_long(row):\n",
    "    return segments_dict[row[\"SEGMENTID\"]][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d33f7cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_merged[\"lat\"] = traffic_merged.apply(add_lat, axis=1)\n",
    "traffic_merged[\"long\"] = traffic_merged.apply(add_long, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f5b021",
   "metadata": {},
   "source": [
    "#### One-hot encoding conditions (the only categorical variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "67bfe535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_clear(row):\n",
    "    return 1 if row[\"conditions\"]==\"Clear\" else 0\n",
    "def is_overcast(row):\n",
    "    return 1 if row[\"conditions\"]==\"Overcast\" else 0\n",
    "def is_partcloud(row):\n",
    "    return 1 if row[\"conditions\"]==\"Partially cloudy\" else 0\n",
    "def is_rainovercase(row):\n",
    "    return 1 if row[\"conditions\"]==\"Rain, Overcast\" else 0\n",
    "def is_snowovercast(row):\n",
    "    return 1 if row[\"conditions\"]==\"Snow, Overcast\" else 0\n",
    "def is_snowrainovercast(row):\n",
    "    return 1 if row[\"conditions\"]==\"Snow, Rain, Overcast\" else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "021517a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_merged[\"is_clear\"] = traffic_merged.apply(is_clear, axis=1)\n",
    "traffic_merged[\"is_overcast\"] = traffic_merged.apply(is_overcast, axis=1)\n",
    "traffic_merged[\"is_partcloud\"] = traffic_merged.apply(is_partcloud, axis=1)\n",
    "traffic_merged[\"is_rainovercase\"] = traffic_merged.apply(is_rainovercase, axis=1)\n",
    "traffic_merged[\"is_snowovercast\"] = traffic_merged.apply(is_snowovercast, axis=1)\n",
    "traffic_merged[\"is_snowrainovercast\"] = traffic_merged.apply(is_snowrainovercast, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ecb3551f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conditions</th>\n",
       "      <th>is_clear</th>\n",
       "      <th>is_overcast</th>\n",
       "      <th>is_partcloud</th>\n",
       "      <th>is_rainovercase</th>\n",
       "      <th>is_snowovercast</th>\n",
       "      <th>is_snowrainovercast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2433537</th>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093168</th>\n",
       "      <td>Snow, Rain, Overcast</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850637</th>\n",
       "      <td>Snow, Rain, Overcast</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454340</th>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801653</th>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2166212</th>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239798</th>\n",
       "      <td>Clear</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593838</th>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076877</th>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920466</th>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   conditions  is_clear  is_overcast  is_partcloud  \\\n",
       "2433537      Partially cloudy         0            0             1   \n",
       "1093168  Snow, Rain, Overcast         0            0             0   \n",
       "1850637  Snow, Rain, Overcast         0            0             0   \n",
       "454340       Partially cloudy         0            0             1   \n",
       "801653       Partially cloudy         0            0             1   \n",
       "2166212      Partially cloudy         0            0             1   \n",
       "239798                  Clear         1            0             0   \n",
       "593838       Partially cloudy         0            0             1   \n",
       "2076877      Partially cloudy         0            0             1   \n",
       "1920466      Partially cloudy         0            0             1   \n",
       "\n",
       "         is_rainovercase  is_snowovercast  is_snowrainovercast  \n",
       "2433537                0                0                    0  \n",
       "1093168                0                0                    1  \n",
       "1850637                0                0                    1  \n",
       "454340                 0                0                    0  \n",
       "801653                 0                0                    0  \n",
       "2166212                0                0                    0  \n",
       "239798                 0                0                    0  \n",
       "593838                 0                0                    0  \n",
       "2076877                0                0                    0  \n",
       "1920466                0                0                    0  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_merged[[\"conditions\", \"is_clear\",\"is_overcast\",\"is_partcloud\", \"is_rainovercase\", \"is_snowovercast\", \"is_snowrainovercast\"]].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967966b8",
   "metadata": {},
   "source": [
    "#### Test/Train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "69438779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SPEED', 'temp', 'feelslike', 'dew', 'humidity', 'precip', 'snowdepth',\n",
       "       'windgust', 'sealevelpressure', 'cloudcover', 'visibility',\n",
       "       'solarradiation', 'solarenergy', 'uvindex', 'weekday', 'time_of_day',\n",
       "       'lat', 'long', 'is_clear', 'is_overcast', 'is_partcloud',\n",
       "       'is_rainovercase', 'is_snowovercast', 'is_snowrainovercast'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_merged = traffic_merged.drop(['TIME', 'SEGMENTID', 'conditions', 'std_datetime', 'preciptype'], axis=1)\n",
    "traffic_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "99d3c5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(569)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9c4b603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proportion of the dataset to reserve for testing. We can change this later\n",
    "test_proportion = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "21015b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2577601"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A count to make sure we don't lose any indices\n",
    "len(traffic_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e067ba85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2577601])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test/train splits, with the count at the end to make sure we have the same number of indices at the end\n",
    "permutation = np.random.permutation(range(len(traffic_merged)))\n",
    "test_indicies = permutation[:int(test_proportion * len(traffic_merged))]\n",
    "train_indicies = permutation[int(test_proportion * len(traffic_merged)):]\n",
    "np.unique(len(test_indicies)+len(train_indicies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "dc7c2be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our test dataframe is test_df, and the train dataframe is train_df\n",
    "test_df = traffic_merged.iloc[test_indicies]\n",
    "train_df = traffic_merged.iloc[train_indicies]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04a4930",
   "metadata": {},
   "source": [
    "## Actual Stepwise Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "960f2dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_X = train_df.drop([\"SPEED\"],axis=1)\n",
    "Y = train_df[\"SPEED\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ec5e817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_e = alpha_r = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093106dc",
   "metadata": {},
   "source": [
    "Forward stepwise regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cbb58f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization phase: we first find the predictor with lowest p-value and insert into our model\n",
      "We now begin forward stepwise regression\n",
      "current predictors being used: ['temp']\n",
      "Forward step\n",
      "Lowest p value found is from variable feelslike with value 0.0\n",
      "this is lower than alpha_e= 0.05 so we add it to our model\n",
      "current predictors being used: ['temp', 'feelslike']\n",
      "Forward step\n",
      "Lowest p value found is from variable cloudcover with value 0.0\n",
      "this is lower than alpha_e= 0.05 so we add it to our model\n",
      "current predictors being used: ['temp', 'feelslike', 'cloudcover']\n",
      "Forward step\n",
      "Lowest p value found is from variable solarradiation with value 0.0\n",
      "this is lower than alpha_e= 0.05 so we add it to our model\n",
      "current predictors being used: ['temp', 'feelslike', 'cloudcover', 'solarradiation']\n",
      "Forward step\n",
      "Lowest p value found is from variable weekday with value 0.0\n",
      "this is lower than alpha_e= 0.05 so we add it to our model\n",
      "current predictors being used: ['temp', 'feelslike', 'cloudcover', 'solarradiation', 'weekday']\n",
      "Forward step\n",
      "Lowest p value found is from variable time_of_day with value 0.0\n",
      "this is lower than alpha_e= 0.05 so we add it to our model\n",
      "current predictors being used: ['temp', 'feelslike', 'cloudcover', 'solarradiation', 'weekday', 'time_of_day']\n",
      "Forward step\n",
      "Lowest p value found is from variable lat with value 0.0\n",
      "this is lower than alpha_e= 0.05 so we add it to our model\n",
      "current predictors being used: ['temp', 'feelslike', 'cloudcover', 'solarradiation', 'weekday', 'time_of_day', 'lat']\n",
      "Forward step\n",
      "Lowest p value found is from variable is_rainovercase with value 7.662370875431618e-227\n",
      "this is lower than alpha_e= 0.05 so we add it to our model\n",
      "current predictors being used: ['temp', 'feelslike', 'cloudcover', 'solarradiation', 'weekday', 'time_of_day', 'lat', 'is_rainovercase']\n",
      "Forward step\n",
      "Lowest p value found is from variable long with value 3.5130371017996017e-96\n",
      "this is lower than alpha_e= 0.05 so we add it to our model\n",
      "current predictors being used: ['temp', 'feelslike', 'cloudcover', 'solarradiation', 'weekday', 'time_of_day', 'lat', 'is_rainovercase', 'long']\n",
      "Forward step\n",
      "Lowest p value found is from variable visibility with value 1.0813564130260864e-87\n",
      "this is lower than alpha_e= 0.05 so we add it to our model\n",
      "current predictors being used: ['temp', 'feelslike', 'cloudcover', 'solarradiation', 'weekday', 'time_of_day', 'lat', 'is_rainovercase', 'long', 'visibility']\n",
      "Forward step\n",
      "Lowest p value found is from variable is_clear with value 1.7711620615914524e-41\n",
      "this is lower than alpha_e= 0.05 so we add it to our model\n",
      "current predictors being used: ['temp', 'feelslike', 'cloudcover', 'solarradiation', 'weekday', 'time_of_day', 'lat', 'is_rainovercase', 'long', 'visibility', 'is_clear']\n",
      "Forward step\n",
      "Lowest p value found is from variable is_partcloud with value 5.149475660967831e-64\n",
      "this is lower than alpha_e= 0.05 so we add it to our model\n",
      "current predictors being used: ['temp', 'feelslike', 'cloudcover', 'solarradiation', 'weekday', 'time_of_day', 'lat', 'is_rainovercase', 'long', 'visibility', 'is_clear', 'is_partcloud']\n",
      "Forward step\n",
      "Lowest p value found is from variable sealevelpressure with value 8.714072352994586e-22\n",
      "this is lower than alpha_e= 0.05 so we add it to our model\n",
      "current predictors being used: ['temp', 'feelslike', 'cloudcover', 'solarradiation', 'weekday', 'time_of_day', 'lat', 'is_rainovercase', 'long', 'visibility', 'is_clear', 'is_partcloud', 'sealevelpressure']\n",
      "Forward step\n",
      "Lowest p value found is from variable snowdepth with value 4.2592604245028444e-23\n",
      "this is lower than alpha_e= 0.05 so we add it to our model\n",
      "current predictors being used: ['temp', 'feelslike', 'cloudcover', 'solarradiation', 'weekday', 'time_of_day', 'lat', 'is_rainovercase', 'long', 'visibility', 'is_clear', 'is_partcloud', 'sealevelpressure', 'snowdepth']\n",
      "Forward step\n",
      "Lowest p value found is from variable is_snowovercast with value 5.20016383765415e-16\n",
      "this is lower than alpha_e= 0.05 so we add it to our model\n",
      "current predictors being used: ['temp', 'feelslike', 'cloudcover', 'solarradiation', 'weekday', 'time_of_day', 'lat', 'is_rainovercase', 'long', 'visibility', 'is_clear', 'is_partcloud', 'sealevelpressure', 'snowdepth', 'is_snowovercast']\n",
      "Forward step\n",
      "Lowest p value found is from variable precip with value 3.3540597043786032e-12\n",
      "this is lower than alpha_e= 0.05 so we add it to our model\n",
      "current predictors being used: ['temp', 'feelslike', 'cloudcover', 'solarradiation', 'weekday', 'time_of_day', 'lat', 'is_rainovercase', 'long', 'visibility', 'is_clear', 'is_partcloud', 'sealevelpressure', 'snowdepth', 'is_snowovercast', 'precip']\n",
      "Forward step\n",
      "Lowest p value found is from variable windgust with value 1.1298197545693738e-08\n",
      "this is lower than alpha_e= 0.05 so we add it to our model\n",
      "current predictors being used: ['temp', 'feelslike', 'cloudcover', 'solarradiation', 'weekday', 'time_of_day', 'lat', 'is_rainovercase', 'long', 'visibility', 'is_clear', 'is_partcloud', 'sealevelpressure', 'snowdepth', 'is_snowovercast', 'precip', 'windgust']\n",
      "Forward step\n",
      "Lowest p value found is from variable humidity with value 5.703228020839076e-10\n",
      "this is lower than alpha_e= 0.05 so we add it to our model\n",
      "current predictors being used: ['temp', 'feelslike', 'cloudcover', 'solarradiation', 'weekday', 'time_of_day', 'lat', 'is_rainovercase', 'long', 'visibility', 'is_clear', 'is_partcloud', 'sealevelpressure', 'snowdepth', 'is_snowovercast', 'precip', 'windgust', 'humidity']\n",
      "Forward step\n",
      "Lowest p value found is from variable is_snowrainovercast with value 0.0025064149336145236\n",
      "this is lower than alpha_e= 0.05 so we add it to our model\n",
      "current predictors being used: ['temp', 'feelslike', 'cloudcover', 'solarradiation', 'weekday', 'time_of_day', 'lat', 'is_rainovercase', 'long', 'visibility', 'is_clear', 'is_partcloud', 'sealevelpressure', 'snowdepth', 'is_snowovercast', 'precip', 'windgust', 'humidity', 'is_snowrainovercast']\n",
      "Forward step\n",
      "Lowest p value found is from variable is_overcast with value 0.0\n",
      "this is lower than alpha_e= 0.05 so we add it to our model\n",
      "current predictors being used: ['temp', 'feelslike', 'cloudcover', 'solarradiation', 'weekday', 'time_of_day', 'lat', 'is_rainovercase', 'long', 'visibility', 'is_clear', 'is_partcloud', 'sealevelpressure', 'snowdepth', 'is_snowovercast', 'precip', 'windgust', 'humidity', 'is_snowrainovercast', 'is_overcast']\n",
      "Forward step\n",
      "Lowest p value found is from variable uvindex with value 0.0088434939590533\n",
      "this is lower than alpha_e= 0.05 so we add it to our model\n",
      "current predictors being used: ['temp', 'feelslike', 'cloudcover', 'solarradiation', 'weekday', 'time_of_day', 'lat', 'is_rainovercase', 'long', 'visibility', 'is_clear', 'is_partcloud', 'sealevelpressure', 'snowdepth', 'is_snowovercast', 'precip', 'windgust', 'humidity', 'is_snowrainovercast', 'is_overcast', 'uvindex']\n",
      "Forward step\n",
      "Lowest p value found is from variable solarenergy with value 0.5432853203455175\n",
      "This is higher than alpha_e= 0.05 so we terminate procedure here\n",
      "Final set of predictors being used: ['temp', 'feelslike', 'cloudcover', 'solarradiation', 'weekday', 'time_of_day', 'lat', 'is_rainovercase', 'long', 'visibility', 'is_clear', 'is_partcloud', 'sealevelpressure', 'snowdepth', 'is_snowovercast', 'precip', 'windgust', 'humidity', 'is_snowrainovercast', 'is_overcast', 'uvindex']\n"
     ]
    }
   ],
   "source": [
    "in_model = [] #variables in our model\n",
    "out_model = train_df_X.columns.tolist() #variables not in (outside) our model\n",
    "#print(out_model)\n",
    "\n",
    "#Initialization: find which value to begin with\n",
    "print(\"Initialization phase: we first find the predictor with lowest p-value and insert into our model\")\n",
    "lowest_p = 1\n",
    "new_param = ''\n",
    "for i in out_model:\n",
    "    #print(i)\n",
    "    X = train_df_X[[i]]\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.OLS(Y, X).fit()\n",
    "    if(model.pvalues[i] < lowest_p):\n",
    "        lowest_p = model.pvalues[i]\n",
    "        new_param = i\n",
    "    #print(model.pvalues[i])\n",
    "  #print(new_param, lowest_p)\n",
    "\n",
    "in_model = [new_param]\n",
    "out_model.remove(new_param)\n",
    "\n",
    "print(\"We now begin forward stepwise regression\")\n",
    "while(True):\n",
    "    print(\"current predictors being used:\", in_model)\n",
    "    #print(in_model)\n",
    "    #print(out_model)\n",
    "\n",
    "    print(\"Forward step\")\n",
    "    #Forward step\n",
    "    lowest_p = 1\n",
    "    new_param = ''\n",
    "    for i in out_model:\n",
    "        #print(\"Considering entering variable \", i)\n",
    "        X = train_df_X[in_model + [i]]\n",
    "        X = sm.add_constant(X)\n",
    "        model = sm.OLS(Y, X).fit()\n",
    "        #print(model.summary())\n",
    "        #print(\"p-value of variable\", i, \"is\", model.pvalues[i])\n",
    "        if(model.pvalues[i] < lowest_p):\n",
    "            lowest_p = model.pvalues[i]\n",
    "            new_param = i\n",
    "    print(\"Lowest p value found is from variable\", new_param, \"with value\", lowest_p)\n",
    "    if(lowest_p < alpha_e):\n",
    "        print(\"this is lower than alpha_e=\", alpha_e, \"so we add it to our model\")\n",
    "        in_model.append(new_param)\n",
    "        out_model.remove(new_param)\n",
    "    else:\n",
    "        print(\"This is higher than alpha_e=\", alpha_e, \"so we terminate procedure here\")\n",
    "        break\n",
    "\n",
    "print(\"Final set of predictors being used:\", in_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "026b86bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We now begin stepwise regression\n",
      "current predictors being used: ['temp', 'feelslike', 'dew', 'humidity', 'precip', 'snowdepth', 'windgust', 'sealevelpressure', 'cloudcover', 'visibility', 'solarradiation', 'solarenergy', 'uvindex', 'weekday', 'time_of_day', 'lat', 'long', 'is_clear', 'is_overcast', 'is_partcloud', 'is_rainovercase', 'is_snowovercast', 'is_snowrainovercast']\n",
      "Backward step\n",
      "With the new model, p-value found greater than alpha_r= 0.05\n",
      "Remove variable dew with p-value 0.9746473843975114\n",
      "With the new model, p-value found greater than alpha_r= 0.05\n",
      "Remove variable cloudcover with p-value 0.5209271513338615\n",
      "With the new model, p-value found greater than alpha_r= 0.05\n",
      "Remove variable solarenergy with p-value 0.5437612672128098\n",
      "current predictors being used: ['temp', 'feelslike', 'humidity', 'precip', 'snowdepth', 'windgust', 'sealevelpressure', 'visibility', 'solarradiation', 'uvindex', 'weekday', 'time_of_day', 'lat', 'long', 'is_clear', 'is_overcast', 'is_partcloud', 'is_rainovercase', 'is_snowovercast', 'is_snowrainovercast']\n",
      "Backward step\n",
      "No variables removed. All p-values remain statistically significant at value above alpha_r= 0.05\n",
      "Final set of predictors being used: ['temp', 'feelslike', 'humidity', 'precip', 'snowdepth', 'windgust', 'sealevelpressure', 'visibility', 'solarradiation', 'uvindex', 'weekday', 'time_of_day', 'lat', 'long', 'is_clear', 'is_overcast', 'is_partcloud', 'is_rainovercase', 'is_snowovercast', 'is_snowrainovercast']\n"
     ]
    }
   ],
   "source": [
    "out_model = [] #variables in our model\n",
    "in_model = train_df_X.columns.tolist() #variables not in (outside) our model\n",
    "\n",
    "\n",
    "print(\"We now begin stepwise regression\")\n",
    "while(True):\n",
    "    print(\"current predictors being used:\", in_model)\n",
    "  \n",
    "    print(\"Backward step\")\n",
    "    #Backward step\n",
    "    remove_these = []\n",
    "    X = train_df_X[in_model]\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.OLS(Y, X).fit()\n",
    "    for i in in_model:\n",
    "        #print(\"Considering removing variable\", i)\n",
    "        #print(\"p-value of variable\", i, \"is\", model.pvalues[i])\n",
    "        if(model.pvalues[i] > alpha_r):\n",
    "            print(\"With the new model, p-value found greater than alpha_r=\", alpha_r)\n",
    "            print(\"Remove variable\", i, \"with p-value\", model.pvalues[i])\n",
    "            remove_these.append(i)\n",
    "    if(remove_these == []):\n",
    "        print(\"No variables removed. All p-values remain statistically significant at value above alpha_r=\", alpha_r)\n",
    "        break\n",
    "    for i in remove_these:\n",
    "        out_model.append(i)\n",
    "        in_model.remove(i)\n",
    "print(\"Final set of predictors being used:\", in_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f8e34e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.029</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.029</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   3230.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 10 Apr 2024</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:44:54</td>     <th>  Log-Likelihood:    </th> <td>-7.1181e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>2062081</td>     <th>  AIC:               </th>  <td>1.424e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>2062061</td>     <th>  BIC:               </th>  <td>1.424e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    19</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>               <td>  636.5215</td> <td>    7.290</td> <td>   87.320</td> <td> 0.000</td> <td>  622.234</td> <td>  650.809</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>temp</th>                <td>   -0.0241</td> <td>    0.004</td> <td>   -6.112</td> <td> 0.000</td> <td>   -0.032</td> <td>   -0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>feelslike</th>           <td>    0.0169</td> <td>    0.003</td> <td>    5.438</td> <td> 0.000</td> <td>    0.011</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>humidity</th>            <td>    0.0030</td> <td>    0.000</td> <td>    6.138</td> <td> 0.000</td> <td>    0.002</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>precip</th>              <td>    8.6972</td> <td>    1.371</td> <td>    6.343</td> <td> 0.000</td> <td>    6.010</td> <td>   11.384</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>snowdepth</th>           <td>   -0.2898</td> <td>    0.029</td> <td>   -9.867</td> <td> 0.000</td> <td>   -0.347</td> <td>   -0.232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>windgust</th>            <td>   -0.0079</td> <td>    0.001</td> <td>   -6.269</td> <td> 0.000</td> <td>   -0.010</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sealevelpressure</th>    <td>    0.0099</td> <td>    0.001</td> <td>    9.798</td> <td> 0.000</td> <td>    0.008</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>visibility</th>          <td>    0.0613</td> <td>    0.004</td> <td>   15.546</td> <td> 0.000</td> <td>    0.054</td> <td>    0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>solarradiation</th>      <td>   -0.0021</td> <td>    0.000</td> <td>   -9.293</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>uvindex</th>             <td>    0.0563</td> <td>    0.022</td> <td>    2.574</td> <td> 0.010</td> <td>    0.013</td> <td>    0.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weekday</th>             <td>    0.1145</td> <td>    0.003</td> <td>   38.255</td> <td> 0.000</td> <td>    0.109</td> <td>    0.120</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>time_of_day</th>         <td>-1.682e-05</td> <td> 2.72e-07</td> <td>  -61.759</td> <td> 0.000</td> <td>-1.74e-05</td> <td>-1.63e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lat</th>                 <td>  -12.8775</td> <td>    0.070</td> <td> -182.984</td> <td> 0.000</td> <td>  -13.015</td> <td>  -12.740</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>long</th>                <td>    2.1579</td> <td>    0.103</td> <td>   20.876</td> <td> 0.000</td> <td>    1.955</td> <td>    2.360</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_clear</th>            <td>  106.4027</td> <td>    1.215</td> <td>   87.555</td> <td> 0.000</td> <td>  104.021</td> <td>  108.785</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_overcast</th>         <td>  105.7093</td> <td>    1.215</td> <td>   87.001</td> <td> 0.000</td> <td>  103.328</td> <td>  108.091</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_partcloud</th>        <td>  106.0276</td> <td>    1.215</td> <td>   87.263</td> <td> 0.000</td> <td>  103.646</td> <td>  108.409</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_rainovercase</th>     <td>  105.1850</td> <td>    1.215</td> <td>   86.548</td> <td> 0.000</td> <td>  102.803</td> <td>  107.567</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_snowovercast</th>     <td>  107.3632</td> <td>    1.226</td> <td>   87.574</td> <td> 0.000</td> <td>  104.960</td> <td>  109.766</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_snowrainovercast</th> <td>  105.8337</td> <td>    1.216</td> <td>   87.043</td> <td> 0.000</td> <td>  103.451</td> <td>  108.217</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>520682.906</td> <th>  Durbin-Watson:     </th>  <td>   1.999</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>1570231.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td> 1.309</td>   <th>  Prob(JB):          </th>  <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td> 6.379</td>   <th>  Cond. No.          </th>  <td>3.53e+16</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 4.54e-18. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}       &        y         & \\textbf{  R-squared:         } &      0.029   \\\\\n",
       "\\textbf{Model:}               &       OLS        & \\textbf{  Adj. R-squared:    } &      0.029   \\\\\n",
       "\\textbf{Method:}              &  Least Squares   & \\textbf{  F-statistic:       } &      3230.   \\\\\n",
       "\\textbf{Date:}                & Wed, 10 Apr 2024 & \\textbf{  Prob (F-statistic):} &      0.00    \\\\\n",
       "\\textbf{Time:}                &     22:44:54     & \\textbf{  Log-Likelihood:    } & -7.1181e+06  \\\\\n",
       "\\textbf{No. Observations:}    &     2062081      & \\textbf{  AIC:               } &  1.424e+07   \\\\\n",
       "\\textbf{Df Residuals:}        &     2062061      & \\textbf{  BIC:               } &  1.424e+07   \\\\\n",
       "\\textbf{Df Model:}            &          19      & \\textbf{                     } &              \\\\\n",
       "\\textbf{Covariance Type:}     &    nonrobust     & \\textbf{                     } &              \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                              & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}                &     636.5215  &        7.290     &    87.320  &         0.000        &      622.234    &      650.809     \\\\\n",
       "\\textbf{temp}                 &      -0.0241  &        0.004     &    -6.112  &         0.000        &       -0.032    &       -0.016     \\\\\n",
       "\\textbf{feelslike}            &       0.0169  &        0.003     &     5.438  &         0.000        &        0.011    &        0.023     \\\\\n",
       "\\textbf{humidity}             &       0.0030  &        0.000     &     6.138  &         0.000        &        0.002    &        0.004     \\\\\n",
       "\\textbf{precip}               &       8.6972  &        1.371     &     6.343  &         0.000        &        6.010    &       11.384     \\\\\n",
       "\\textbf{snowdepth}            &      -0.2898  &        0.029     &    -9.867  &         0.000        &       -0.347    &       -0.232     \\\\\n",
       "\\textbf{windgust}             &      -0.0079  &        0.001     &    -6.269  &         0.000        &       -0.010    &       -0.005     \\\\\n",
       "\\textbf{sealevelpressure}     &       0.0099  &        0.001     &     9.798  &         0.000        &        0.008    &        0.012     \\\\\n",
       "\\textbf{visibility}           &       0.0613  &        0.004     &    15.546  &         0.000        &        0.054    &        0.069     \\\\\n",
       "\\textbf{solarradiation}       &      -0.0021  &        0.000     &    -9.293  &         0.000        &       -0.002    &       -0.002     \\\\\n",
       "\\textbf{uvindex}              &       0.0563  &        0.022     &     2.574  &         0.010        &        0.013    &        0.099     \\\\\n",
       "\\textbf{weekday}              &       0.1145  &        0.003     &    38.255  &         0.000        &        0.109    &        0.120     \\\\\n",
       "\\textbf{time\\_of\\_day}        &   -1.682e-05  &     2.72e-07     &   -61.759  &         0.000        &    -1.74e-05    &    -1.63e-05     \\\\\n",
       "\\textbf{lat}                  &     -12.8775  &        0.070     &  -182.984  &         0.000        &      -13.015    &      -12.740     \\\\\n",
       "\\textbf{long}                 &       2.1579  &        0.103     &    20.876  &         0.000        &        1.955    &        2.360     \\\\\n",
       "\\textbf{is\\_clear}            &     106.4027  &        1.215     &    87.555  &         0.000        &      104.021    &      108.785     \\\\\n",
       "\\textbf{is\\_overcast}         &     105.7093  &        1.215     &    87.001  &         0.000        &      103.328    &      108.091     \\\\\n",
       "\\textbf{is\\_partcloud}        &     106.0276  &        1.215     &    87.263  &         0.000        &      103.646    &      108.409     \\\\\n",
       "\\textbf{is\\_rainovercase}     &     105.1850  &        1.215     &    86.548  &         0.000        &      102.803    &      107.567     \\\\\n",
       "\\textbf{is\\_snowovercast}     &     107.3632  &        1.226     &    87.574  &         0.000        &      104.960    &      109.766     \\\\\n",
       "\\textbf{is\\_snowrainovercast} &     105.8337  &        1.216     &    87.043  &         0.000        &      103.451    &      108.217     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 520682.906 & \\textbf{  Durbin-Watson:     } &      1.999   \\\\\n",
       "\\textbf{Prob(Omnibus):} &    0.000   & \\textbf{  Jarque-Bera (JB):  } & 1570231.022  \\\\\n",
       "\\textbf{Skew:}          &    1.309   & \\textbf{  Prob(JB):          } &       0.00   \\\\\n",
       "\\textbf{Kurtosis:}      &    6.379   & \\textbf{  Cond. No.          } &   3.53e+16   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The smallest eigenvalue is 4.54e-18. This might indicate that there are \\newline\n",
       " strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.029\n",
       "Model:                            OLS   Adj. R-squared:                  0.029\n",
       "Method:                 Least Squares   F-statistic:                     3230.\n",
       "Date:                Wed, 10 Apr 2024   Prob (F-statistic):               0.00\n",
       "Time:                        22:44:54   Log-Likelihood:            -7.1181e+06\n",
       "No. Observations:             2062081   AIC:                         1.424e+07\n",
       "Df Residuals:                 2062061   BIC:                         1.424e+07\n",
       "Df Model:                          19                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=======================================================================================\n",
       "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "const                 636.5215      7.290     87.320      0.000     622.234     650.809\n",
       "temp                   -0.0241      0.004     -6.112      0.000      -0.032      -0.016\n",
       "feelslike               0.0169      0.003      5.438      0.000       0.011       0.023\n",
       "humidity                0.0030      0.000      6.138      0.000       0.002       0.004\n",
       "precip                  8.6972      1.371      6.343      0.000       6.010      11.384\n",
       "snowdepth              -0.2898      0.029     -9.867      0.000      -0.347      -0.232\n",
       "windgust               -0.0079      0.001     -6.269      0.000      -0.010      -0.005\n",
       "sealevelpressure        0.0099      0.001      9.798      0.000       0.008       0.012\n",
       "visibility              0.0613      0.004     15.546      0.000       0.054       0.069\n",
       "solarradiation         -0.0021      0.000     -9.293      0.000      -0.002      -0.002\n",
       "uvindex                 0.0563      0.022      2.574      0.010       0.013       0.099\n",
       "weekday                 0.1145      0.003     38.255      0.000       0.109       0.120\n",
       "time_of_day         -1.682e-05   2.72e-07    -61.759      0.000   -1.74e-05   -1.63e-05\n",
       "lat                   -12.8775      0.070   -182.984      0.000     -13.015     -12.740\n",
       "long                    2.1579      0.103     20.876      0.000       1.955       2.360\n",
       "is_clear              106.4027      1.215     87.555      0.000     104.021     108.785\n",
       "is_overcast           105.7093      1.215     87.001      0.000     103.328     108.091\n",
       "is_partcloud          106.0276      1.215     87.263      0.000     103.646     108.409\n",
       "is_rainovercase       105.1850      1.215     86.548      0.000     102.803     107.567\n",
       "is_snowovercast       107.3632      1.226     87.574      0.000     104.960     109.766\n",
       "is_snowrainovercast   105.8337      1.216     87.043      0.000     103.451     108.217\n",
       "==============================================================================\n",
       "Omnibus:                   520682.906   Durbin-Watson:                   1.999\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1570231.022\n",
       "Skew:                           1.309   Prob(JB):                         0.00\n",
       "Kurtosis:                       6.379   Cond. No.                     3.53e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 4.54e-18. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_df_X[in_model]\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(Y, X).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "064c67c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization phase: we first find the predictor with lowest p-value and insert into our model\n",
      "We now begin stepwise regression\n",
      "current predictors being used: ['temp']\n",
      "Forward step\n",
      "Lowest p value found is from variable feelslike with value 0.0\n",
      "this is lower than alpha_e= 0.05 so we add it to our model\n",
      "Backward step\n",
      "No variables removed. All p-values remain statistically significant at value above alpha_r= 0.05\n",
      "current predictors being used: ['temp', 'feelslike']\n",
      "Forward step\n",
      "Lowest p value found is from variable cloudcover with value 0.0\n",
      "this is lower than alpha_e= 0.05 so we add it to our model\n",
      "Backward step\n",
      "No variables removed. All p-values remain statistically significant at value above alpha_r= 0.05\n",
      "current predictors being used: ['temp', 'feelslike', 'cloudcover']\n",
      "Forward step\n",
      "Lowest p value found is from variable solarradiation with value 0.0\n",
      "this is lower than alpha_e= 0.05 so we add it to our model\n",
      "Backward step\n",
      "No variables removed. All p-values remain statistically significant at value above alpha_r= 0.05\n",
      "current predictors being used: ['temp', 'feelslike', 'cloudcover', 'solarradiation']\n",
      "Forward step\n",
      "Lowest p value found is from variable weekday with value 0.0\n",
      "this is lower than alpha_e= 0.05 so we add it to our model\n",
      "Backward step\n",
      "No variables removed. All p-values remain statistically significant at value above alpha_r= 0.05\n",
      "current predictors being used: ['temp', 'feelslike', 'cloudcover', 'solarradiation', 'weekday']\n",
      "Forward step\n",
      "Lowest p value found is from variable time_of_day with value 0.0\n",
      "this is lower than alpha_e= 0.05 so we add it to our model\n",
      "Backward step\n",
      "No variables removed. All p-values remain statistically significant at value above alpha_r= 0.05\n",
      "current predictors being used: ['temp', 'feelslike', 'cloudcover', 'solarradiation', 'weekday', 'time_of_day']\n",
      "Forward step\n",
      "Lowest p value found is from variable lat with value 0.0\n",
      "this is lower than alpha_e= 0.05 so we add it to our model\n",
      "Backward step\n",
      "No variables removed. All p-values remain statistically significant at value above alpha_r= 0.05\n",
      "current predictors being used: ['temp', 'feelslike', 'cloudcover', 'solarradiation', 'weekday', 'time_of_day', 'lat']\n",
      "Forward step\n",
      "Lowest p value found is from variable is_rainovercase with value 7.662370875431618e-227\n",
      "this is lower than alpha_e= 0.05 so we add it to our model\n",
      "Backward step\n",
      "No variables removed. All p-values remain statistically significant at value above alpha_r= 0.05\n",
      "current predictors being used: ['temp', 'feelslike', 'cloudcover', 'solarradiation', 'weekday', 'time_of_day', 'lat', 'is_rainovercase']\n",
      "Forward step\n",
      "Lowest p value found is from variable long with value 3.5130371017996017e-96\n",
      "this is lower than alpha_e= 0.05 so we add it to our model\n",
      "Backward step\n",
      "No variables removed. All p-values remain statistically significant at value above alpha_r= 0.05\n",
      "current predictors being used: ['temp', 'feelslike', 'cloudcover', 'solarradiation', 'weekday', 'time_of_day', 'lat', 'is_rainovercase', 'long']\n",
      "Forward step\n",
      "Lowest p value found is from variable visibility with value 1.0813564130260864e-87\n",
      "this is lower than alpha_e= 0.05 so we add it to our model\n",
      "Backward step\n",
      "No variables removed. All p-values remain statistically significant at value above alpha_r= 0.05\n",
      "current predictors being used: ['temp', 'feelslike', 'cloudcover', 'solarradiation', 'weekday', 'time_of_day', 'lat', 'is_rainovercase', 'long', 'visibility']\n",
      "Forward step\n",
      "Lowest p value found is from variable is_clear with value 1.7711620615914524e-41\n",
      "this is lower than alpha_e= 0.05 so we add it to our model\n",
      "Backward step\n",
      "No variables removed. All p-values remain statistically significant at value above alpha_r= 0.05\n",
      "current predictors being used: ['temp', 'feelslike', 'cloudcover', 'solarradiation', 'weekday', 'time_of_day', 'lat', 'is_rainovercase', 'long', 'visibility', 'is_clear']\n",
      "Forward step\n",
      "Lowest p value found is from variable is_partcloud with value 5.149475660967831e-64\n",
      "this is lower than alpha_e= 0.05 so we add it to our model\n",
      "Backward step\n",
      "With the new model, p-value found greater than alpha_r= 0.05\n",
      "Remove variable cloudcover with p-value 0.22047840439092894\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [136]\u001b[0m, in \u001b[0;36m<cell line: 22>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m remove_these:\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;66;03m#print(out_model)\u001b[39;00m\n\u001b[0;32m     68\u001b[0m         in_model\u001b[38;5;241m.\u001b[39mappend(i)\n\u001b[1;32m---> 69\u001b[0m         \u001b[43mout_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal set of predictors being used:\u001b[39m\u001b[38;5;124m\"\u001b[39m, in_model)\n",
      "\u001b[1;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "in_model = [] #variables in our model\n",
    "out_model = train_df_X.columns.tolist() #variables not in (outside) our model\n",
    "\n",
    "#Initialization: find which value to begin with\n",
    "print(\"Initialization phase: we first find the predictor with lowest p-value and insert into our model\")\n",
    "lowest_p = 1\n",
    "new_param = ''\n",
    "for i in out_model:\n",
    "    X = train_df_X[[i]]\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.OLS(Y, X).fit()\n",
    "    if(model.pvalues[i] < lowest_p):\n",
    "        lowest_p = model.pvalues[i]\n",
    "        new_param = i\n",
    "    #print(model.pvalues[i])\n",
    "  #print(new_param, lowest_p)\n",
    "\n",
    "in_model = [new_param]\n",
    "out_model.remove(new_param)\n",
    "\n",
    "print(\"We now begin stepwise regression\")\n",
    "while(True):\n",
    "    print(\"current predictors being used:\", in_model)\n",
    "    #print(in_model)\n",
    "    #print(out_model)\n",
    "\n",
    "    print(\"Forward step\")\n",
    "    #Forward step\n",
    "    lowest_p = 1\n",
    "    new_param = ''\n",
    "    for i in out_model:\n",
    "        #print(\"Considering entering variable \", i)\n",
    "        X = train_df_X[in_model + [i]]\n",
    "        X = sm.add_constant(X)\n",
    "        model = sm.OLS(Y, X).fit()\n",
    "        #print(model.summary())\n",
    "        #print(\"p-value of variable\", i, \"is\", model.pvalues[i])\n",
    "        if(model.pvalues[i] < lowest_p):\n",
    "            lowest_p = model.pvalues[i]\n",
    "            new_param = i\n",
    "    print(\"Lowest p value found is from variable\", new_param, \"with value\", lowest_p)\n",
    "    if(lowest_p < alpha_e):\n",
    "        print(\"this is lower than alpha_e=\", alpha_e, \"so we add it to our model\")\n",
    "        in_model.append(new_param)\n",
    "        out_model.remove(new_param)\n",
    "    else:\n",
    "        print(\"This is higher than alpha_e=\", alpha_e, \"so we terminate procedure here\")\n",
    "        break\n",
    "\n",
    "\n",
    "    print(\"Backward step\")\n",
    "    #Backward step\n",
    "    remove_these = []\n",
    "    X = train_df_X[in_model]\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.OLS(Y, X).fit()\n",
    "    for i in in_model:\n",
    "        #print(\"Considering removing variable\", i)\n",
    "        #print(\"p-value of variable\", i, \"is\", model.pvalues[i])\n",
    "        if(model.pvalues[i] > alpha_r):\n",
    "            print(\"With the new model, p-value found greater than alpha_r=\", alpha_r)\n",
    "            print(\"Remove variable\", i, \"with p-value\", model.pvalues[i])\n",
    "            remove_these.append(i)\n",
    "    if(remove_these == []):\n",
    "        print(\"No variables removed. All p-values remain statistically significant at value above alpha_r=\", alpha_r)\n",
    "    for i in remove_these:\n",
    "        print(out_model)\n",
    "        in_model.append(i)\n",
    "        out_model.remove(i)\n",
    "\n",
    "print(\"Final set of predictors being used:\", in_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e02a276",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
